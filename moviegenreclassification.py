# -*- coding: utf-8 -*-
"""MovieGenreClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1guDYG07E0HbJUYj5DXlLBNO0eSs6NQSd
"""

import os
os.listdir('/content/Dataset')

import numpy as np
import pandas as pd
import os
import warnings
warnings.filterwarnings('ignore')
data=pd.read_csv('/content/Dataset/description.txt')
data

def load_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        data = f.readlines()  # Read all lines into a list

    # Process each line: strip whitespace and split by ':::'
    data = [line.strip().split(':::') for line in data]

    return data  # Return processed data

# Load training dataset
train_data = load_data("/content/Dataset/train_data.txt")
train_df = pd.DataFrame(train_data, columns=['ID', 'Title', 'Genre', 'Description'])

# Load test dataset
test_data = load_data("/content/Dataset/test_data.txt")
test_df = pd.DataFrame(test_data, columns=['ID', 'Title', 'Description'])  # Fixed unclosed parenthesis

# Load test solution dataset
test_solution = load_data('/content/Dataset/test_data_solution.txt')
test_solution_df = pd.DataFrame(test_solution, columns=['ID', 'Title', 'Genre', 'Description'])

print("Training Data:")
train_df

print("\nTest Data:")
test_df

print("\nTest Solution Data:")
test_solution_df

"""Feature Extraction:TF-IDF"""

from sklearn.feature_extraction.text import TfidfVectorizer  # Corrected import

# Initialize TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=10000)

# Transform text descriptions into numerical features
X_train_tfidf = vectorizer.fit_transform(train_df["Description"])
X_test_tfidf = vectorizer.transform(test_df["Description"])

# Display the shape of transformed data
print(f"Training data shape: {X_train_tfidf.shape}")
print(f"Test data shape: {X_test_tfidf.shape}")

"""Encoding the target labels"""

from sklearn.preprocessing import LabelEncoder  # Use MultiLabelBinarizer for multi-label genres
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform([genre.split("|") for genre in train_df["Genre"]])
print(f"Unique geners in the training data: {label_encoder.classes_}")

"""Model Building- Logistic Regression

"""

from sklearn.linear_model import LogisticRegression
lr_model=LogisticRegression(max_iter=200)
lr_model.fit(X_train_tfidf,y_train)
y_pred=lr_model.predict(X_test_tfidf)
predicted_genres=label_encoder.inverse_transform(y_pred)
test_df['Predicted_Genre']=predicted_genres
test_df

test_df['Predicted_Genre']=predicted_genres
merge_df = pd.merge(test_solution_df[['ID','Genre']], test_df[['ID','Predicted_Genre']], on='ID')
merge_df

"""Model Evaluation-Logistic Regression"""

from sklearn.metrics import accuracy_score, precision_score,classification_report
accuracy = accuracy_score(merge_df['Genre'], merge_df['Predicted_Genre'])
print(f"Accuracy:{accuracy:.4f}")
print("/nClassification Report:")
print(classification_report(merge_df['Genre'], merge_df['Predicted_Genre']))

"""Model Building-Nayie Bayes"""

from sklearn.naive_bayes import MultinomialNB
nb_model=MultinomialNB()
nb_model.fit(X_train_tfidf,y_train)

# Predict on test data
y_pred_nb = nb_model.predict(X_test_tfidf)

# Convert numerical labels back to original genre names
predicted_genres_nb = label_encoder.inverse_transform(y_pred_nb)

# Store predictions in test DataFrame
test_df['Predicted_Genre_NB'] = predicted_genres_nb

# Merge with solution DataFrame on 'ID'
merged_df_nb = pd.merge(test_solution_df, test_df[['ID', 'Predicted_Genre_NB']], on='ID')

"""Model Evaluation_Navie Bayes

"""

from sklearn.metrics import accuracy_score, precision_score, classification_report
accuracy_nb = accuracy_score(merged_df_nb['Genre'], merged_df_nb['Predicted_Genre_NB'])
print(f"Naive Bayes Accuracy: {accuracy_nb:.4f}")
print(f"Naive Bayes Classification Report:")
print(classification_report(merged_df_nb['Genre'], merged_df_nb['Predicted_Genre_NB']))

"""Support Vector Machine"""

from sklearn.svm import SVC
svm_model=SVC(kernel='linear')
svm_model.fit(X_train_tfidf,y_train)

# Predict genres using SVM model
y_pred_svm = svm_model.predict(X_test_tfidf)

# Convert numerical predictions back to original genre labels
predicted_genres_svm = label_encoder.inverse_transform(y_pred_svm)

# Add predictions to test DataFrame
test_df['Predicted_Genre_SVM'] = predicted_genres_svm

# Merge predictions with the test solution DataFrame
merged_df_svm = pd.merge(test_solution_df, test_df[['ID', 'Predicted_Genre_SVM']], on='ID', how='left')

"""Model Evaluation-SVM"""

from sklearn.metrics import accuracy_score, precision_score, classification_report
accuracy_svm = accuracy_score(merged_df_svm['Genre'], merged_df_svm['Predicted_Genre_SVM'])
print(f"SVM Accuracy: {accuracy_svm:.4f}")
print(f"SVM Classification Report:")
print(classification_report(merged_df_svm['Genre'], merged_df_svm['Predicted_Genre_SVM']))

"""Test Cases"""

# Assuming the models (lr_model, nb_model, svm_model) have already been trained
# and that X_test_tfidf is the TF-IDF representation of the test data.

zoner_Description = [
    'Explosive fight scenes in the city streets',  # Action
    'A haunted mansion that traps its visitors',   # Horror
    'A brave adventurer in search of lost treasure',  # Adventure
    'A forbidden romance in the 1920s',  # Romance
    'A daring rescue mission with a love interest'  # Action
]

# Step 1: Vectorize the new test data using the same vectorizer
test_data_tfidf = vectorizer.transform(zoner_Description)  # Transform descriptions into TF-IDF features

# Step 2: Predict genres using each model
y_pred_ir = lr_model.predict(test_data_tfidf)  # Predict using Logistic Regression
predicted_genres_ir = label_encoder.inverse_transform(y_pred_ir)  # Convert to genre labels

y_pred_nb = nb_model.predict(test_data_tfidf)  # Predict using Naive Bayes
predicted_genres_nb = label_encoder.inverse_transform(y_pred_nb)  # Convert to genre labels

y_pred_svm = svm_model.predict(test_data_tfidf)  # Predict using SVM
predicted_genres_svm = label_encoder.inverse_transform(y_pred_svm)  # Convert to genre labels

# Print predictions
print("Predicted Genres using Logistic Regression:", predicted_genres_ir)
print("Predicted Genres using Naive Bayes:", predicted_genres_nb)
print("Predicted Genres using SVM:", predicted_genres_svm)
print()

# Display predictions for each story
for i, message in enumerate(zoner_Description):
    print(f"Story: {message}")
    print(f"Status: \tNaive Bayes Prediction: {predicted_genres_nb[i]}")
    print(f"\t\tLogistic Regression Prediction: {predicted_genres_ir[i]}")
    print(f"\t\tSVM Prediction: {predicted_genres_svm[i]}")
    print("=" * 100)  # Separates each message

# Assuming the models (lr_model, nb_model, svm_model) have already been trained
# and that the vectorizer and label_encoder are available.

def predict_genre(user_input):
    # Step 1: Vectorize the user input
    input_tfidf = vectorizer.transform([user_input])  # Convert input to TF-IDF features

    # Step 2: Predict genres using each model
    y_pred_nb = nb_model.predict(input_tfidf)
    predicted_genre_nb = label_encoder.inverse_transform(y_pred_nb)[0]

    y_pred_ir = lr_model.predict(input_tfidf)
    predicted_genre_ir = label_encoder.inverse_transform(y_pred_ir)[0]

    y_pred_svm = svm_model.predict(input_tfidf)
    predicted_genre_svm = label_encoder.inverse_transform(y_pred_svm)[0]

    # Print predictions
    print("\nPredictions for the given description:")
    print(f"\tNaive Bayes Prediction: {predicted_genre_nb}")
    print(f"\tLogistic Regression Prediction: {predicted_genre_ir}")
    print(f"\tSVM Prediction: {predicted_genre_svm}")
    print("=" * 80)

# Continuous loop for user input
while True:
    user_description = input("\nEnter a movie/story description (or type 'exit' to quit): ").strip()

    if user_description.lower() == 'exit':
        print("Exiting... Have a great day!")
        break  # Exit the loop

    predict_genre(user_description)  # Call the function with user input

